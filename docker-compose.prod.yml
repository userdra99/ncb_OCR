services:
  # =============================================================================
  # Redis - Using Host Redis (port 6379 already in use)
  # =============================================================================
  # Commented out - using host Redis at localhost:6379 instead
  # To use containerized Redis, uncomment this and change port to 6380
  # redis:
  #   image: redis:7-alpine
  #   container_name: claims-redis-prod
  #   restart: always
  #   ports:
  #     - "127.0.0.1:6380:6379"  # Changed to 6380 to avoid conflict
  #   volumes:
  #     - redis-data:/data
  #   command: >
  #     redis-server
  #     --appendonly yes
  #     --appendfsync everysec
  #     --maxmemory 2gb
  #     --maxmemory-policy allkeys-lru
  #     --save 900 1
  #     --save 300 10
  #     --save 60 10000
  #   healthcheck:
  #     test: ["CMD", "redis-cli", "ping"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 30s
  #   networks:
  #     - claims-network
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '2'
  #         memory: 2G
  #       reservations:
  #         cpus: '1'
  #         memory: 1G
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

  # =============================================================================
  # Claims Data Entry Agent - Production Configuration
  # =============================================================================
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: claims-app-prod
    restart: always
    network_mode: "host"  # Use host network to access host Redis
    # depends_on:
    #   redis:
    #     condition: service_healthy
    ports:
      - "127.0.0.1:8080:8080"  # Only localhost access (use reverse proxy)
      - "127.0.0.1:9090:9090"  # Metrics endpoint
    environment:
      # Application - Production settings
      - APP_ENV=production
      - APP_DEBUG=false
      - LOG_LEVEL=WARNING
      - LOG_FORMAT=json

      # Redis - Using host Redis
      - REDIS_URL=redis://localhost:6379/0
      - REDIS_OCR_QUEUE=claims:ocr_queue
      - REDIS_SUBMISSION_QUEUE=claims:submission_queue
      - REDIS_EXCEPTION_QUEUE=claims:exception_queue

      # OCR - Production optimized
      - OCR_USE_GPU=true
      - OCR_DEFAULT_LANGUAGE=en
      - OCR_DETECTION_THRESHOLD=0.5
      - OCR_RECOGNITION_THRESHOLD=0.5
      - OCR_HIGH_CONFIDENCE_THRESHOLD=0.90
      - OCR_MEDIUM_CONFIDENCE_THRESHOLD=0.75
      - OCR_BATCH_SIZE=8
      - OCR_MAX_IMAGE_SIZE=4096

      # GPU Configuration (Blackwell RTX 5090 compatible)
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - GPU_TYPE=${GPU_TYPE:-}
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

      # Storage
      - TEMP_STORAGE_PATH=/app/data/temp
      - TEMP_FILE_MAX_AGE_HOURS=24

      # NCB JSON Output (Production Mode - No API submission)
      - NCB_JSON_OUTPUT_DIR=/app/data/ncb_pending

      # Admin
      - ADMIN_PORT=8080

      # Monitoring
      - METRICS_ENABLED=true
      - METRICS_PORT=9090
    env_file:
      - .env.production
    volumes:
      # Secrets (writable for OAuth token refresh)
      - ./secrets:/app/secrets

      # Data persistence
      - app-data:/app/data
      - app-logs:/app/logs

      # NCB JSON output (for manual submission - NCB API not ready)
      - ./data/ncb_pending:/app/data/ncb_pending
      - ./data/ncb_processed:/app/data/ncb_processed
      - ./data/ncb_output:/app/data/ncb_output
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
          devices:
            - driver: nvidia
              count: ${GPU_COUNT:-1}
              capabilities: [gpu]
    shm_size: ${SHM_SIZE:-16gb}
    # networks:
    #   - claims-network  # Disabled - using host network mode
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8080/health', timeout=5.0)"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "10"
        compress: "true"
    security_opt:
      - no-new-privileges:true
    read_only: false  # Need write access to /app/data and /app/logs
    tmpfs:
      - /tmp:mode=1777,size=1G

  # =============================================================================
  # OCR Worker (Optional - Separate worker for scaling)
  # =============================================================================
  ocr-worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    restart: always
    network_mode: "host"  # Use host network to access host Redis
    # depends_on:
    #   redis:
    #     condition: service_healthy
    environment:
      - APP_ENV=production
      - APP_DEBUG=false
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
      - REDIS_URL=redis://localhost:6379/0
      - OCR_USE_GPU=true
      - OCR_BATCH_SIZE=8
      # GPU Configuration
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - GPU_TYPE=${GPU_TYPE:-}
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    env_file:
      - .env.production
    volumes:
      - ./secrets:/app/secrets
      - app-data:/app/data
      - app-logs:/app/logs
    command: ["worker", "ocr"]
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '3'
          memory: 6G
        reservations:
          cpus: '2'
          memory: 4G
          devices:
            - driver: nvidia
              count: ${GPU_COUNT:-1}
              capabilities: [gpu]
    shm_size: ${SHM_SIZE:-16gb}
    # networks:
    #   - claims-network  # Disabled - using host network mode
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        compress: "true"
    security_opt:
      - no-new-privileges:true

  # =============================================================================
  # Submission Worker (Optional - Separate worker for NCB submissions)
  # =============================================================================
  submission-worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    restart: always
    network_mode: "host"  # Use host network to access host Redis
    # depends_on:
    #   redis:
    #     condition: service_healthy
    environment:
      - APP_ENV=production
      - APP_DEBUG=false
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
      - REDIS_URL=redis://localhost:6379/0
    env_file:
      - .env.production
    volumes:
      - ./secrets:/app/secrets
      - app-data:/app/data
      - app-logs:/app/logs
    command: ["worker", "submission"]
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    # networks:
    #   - claims-network  # Disabled - using host network mode
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        compress: "true"
    security_opt:
      - no-new-privileges:true

networks:
  claims-network:
    driver: bridge
    internal: false

volumes:
  redis-data:
    driver: local
  app-data:
    driver: local
  app-logs:
    driver: local
